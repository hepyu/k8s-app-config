apiVersion: apps/v1
kind: Deployment
metadata:
  generation: 1
  labels:
    app: kibana
    release: es-min-kibana
  name: es-min-kibana-kibana
  namespace: es-min-kibana
spec:
  #Deployment 在尝试部署新的 ReplicaSet 的时候可能卡住，也不会完成。这可能是因为以下几个因素引起的：
  #无效的引用
  #不可读的 probe failure
  #镜像拉取错误
  #权限不够
  #范围限制
  #程序运行时配置错误
  #探测这种情况的一种方式是:
  #Deployment spec 中指定spec.progressDeadlineSeconds。spec.progressDeadlineSeconds 表示 Deployment controller 等待多少秒才能确定（通过 Deployment status）Deployment进程是卡住的;
  progressDeadlineSeconds: 600
  replicas: 1
  #revisionHistoryLimit 项来指定保留多少旧的ReplicaSet。 余下的将在后台被当作垃圾收集。默认的，所有的revision历史就都会被保留;
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: kibana
      release: es-min-kibana
  strategy:
    rollingUpdate:
      #滚动升级时会先启动25%的pod
      maxSurge: 25%
      #滚动升级时允许的最大Unavailable的pod占比
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: kibana
        release: es-min-kibana
    spec:
      containers:
      - env:
        - name: ELASTICSEARCH_URL
          value: http://es-min-ingest.es-min:9200
        image: kibana:6.4.3
        imagePullPolicy: IfNotPresent
        name: kibana
        ports:
        - containerPort: 5601
          protocol: TCP
        #Kubelet 使用 readiness probe（就绪探针）来确定容器是否已经就绪可以接受流量。
        #只有当 Pod 中的容器都处于就绪状态时 kubelet 才会认定该 Pod处于就绪状态。
        #该信号的作用是控制哪些 Pod应该作为service的后端。如果 Pod 处于非就绪状态，那么它们将会被从 service 的 load balancer中移除。
        readinessProbe:
          exec:
            command:
            - sh
            - -c
            - |
              #!/usr/bin/env bash -e
              http () {
                  local path="${1}"
                  if [ -n "${ELASTIC_USERNAME}" ] && [ -n "${ELASTIC_PASSWORD}" ]; then
                    BASIC_AUTH="-u ${ELASTIC_USERNAME}:${ELASTIC_PASSWORD}"
                  else
                    BASIC_AUTH=''
                  fi
                  curl -XGET -s --fail ${BASIC_AUTH} 127.0.0.1:5601${path}
              }

              http "/app/kibana"
          #探测成功后，最少连续探测失败多少次才被认定为失败。默认是 3。最小值是 1。
          failureThreshold: 3
          #容器启动后第一次执行探测是需要等待多少秒。
          initialDelaySeconds: 10
          #执行探测的频率。默认是10秒，最小1秒。
          periodSeconds: 10
          #探测失败后，最少连续探测成功多少次才被认定为成功。默认是 1。对于 liveness 必须是 1。最小值是 1。
          successThreshold: 3
          #探测超时时间。默认1秒，最小1秒
          timeoutSeconds: 5
        resources:
          limits:
            cpu: "1"
            memory: 1Gi
          requests:
            cpu: 100m
            memory: 500m
        #为了达到一个相当高水平的实用性，特别是为了积极开发应用，快速调试失败是很重要的。
        #除了一般的日志采集，Kubernetes还能通过查出重大错误原因来加速调试，并在某种程度上通过kubectl或者UI陈列出来。
        #可以指定一个’terminationMessagePath’来让容器写下它的“death rattle“，比如声明失败消息，堆栈跟踪，免责条款等等。默认途径是‘/dev/termination-log’。
        terminationMessagePath: /dev/termination-log
        #此字段默认为 “File“，这意味着仅从终止消息文件中检索终止消息。 
        #通过将 terminationMessagePolicy 设置为 “FallbackToLogsOnError“，你就可以告诉 Kubernetes，在容器因错误退出时，
        #如果终止消息文件为空，则使用容器日志输出的最后一块作为终止消息。 日志输出限制为 2048 字节或 80 行，以较小者为准。
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      #如果容器中的进程能够在遇到问题或不健康的情况下自行崩溃，则不一定需要存活探针; kubelet 将根据 Pod 的restartPolicy 自动执行正确的操作。
      restartPolicy: Always
      #scheduler 是 kubernetes 的调度器，主要的任务是把定义的 pod 分配到集群的节点上。
      schedulerName: default-scheduler
      securityContext: {}
      #如果您的Pod通常需要超过30秒才能关闭，请确保增加优雅终止宽限期。可以通过在Pod YAML中设置terminationGracePeriodSeconds选项来实现.
      #如果容器在优雅终止宽限期后仍在运行，则会发送SIGKILL信号并强制删除。与此同时，所有的Kubernetes对象也会被清除。
      terminationGracePeriodSeconds: 30
